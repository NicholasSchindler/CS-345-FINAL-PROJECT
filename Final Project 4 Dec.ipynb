{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "qEnVAWhdTqo4"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "m9i1vAGQUFmQ"
   },
   "outputs": [],
   "source": [
    "def load_and_split_csv(filename):\n",
    "  ham_data = []\n",
    "  spam_data = []\n",
    "\n",
    "  with open(filename, newline = '', encoding = 'latin1') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader, None)\n",
    "\n",
    "    for row in reader:\n",
    "      label, text = row[0].strip().lower(), row[1].strip()\n",
    "      if 'ham' in label:\n",
    "        ham_data.append(text)\n",
    "      elif 'spam' in label:\n",
    "        spam_data.append(text)\n",
    "\n",
    "  return ham_data, spam_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "UQjj3LkZVRHh"
   },
   "outputs": [],
   "source": [
    "def parse_word_frequencies(text_list):\n",
    "    word_counter = Counter()\n",
    "\n",
    "    for text in text_list:\n",
    "        words = re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "        word_counter.update(words)\n",
    "\n",
    "    return dict(word_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "9DFaZIP2VTmu"
   },
   "outputs": [],
   "source": [
    "##### Main #####\n",
    "\n",
    "# Loads the csv and splits it into a ham dataset and a spam dataset.\n",
    "ham, spam = load_and_split_csv(\"spam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "44w3-FlQVWJs"
   },
   "outputs": [],
   "source": [
    "# Get the number of ham and the number of spam messages so we can adjust for frequency.\n",
    "ham_size = len(ham)\n",
    "spam_size = len(spam)\n",
    "\n",
    "# Counts the frequency of each word in ham and spam datasets. The first column is the word, and the second is the count.\n",
    "# Converts everything to lower case so capitalization does not matter.\n",
    "ham_parsed = parse_word_frequencies(ham)\n",
    "spam_parsed = parse_word_frequencies(spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "iLkIJGdEaiJS",
    "outputId": "1fb231d3-1f50-434b-b702-f9f5986f2c5e"
   },
   "outputs": [],
   "source": [
    "# Combine all unique words from both sets\n",
    "all_words = set(ham_parsed.keys()) | set(spam_parsed.keys())\n",
    "\n",
    "# Build dataset rows\n",
    "rows = []\n",
    "for word in all_words:\n",
    "    ham_count = ham_parsed.get(word, 0)\n",
    "    spam_count = spam_parsed.get(word, 0)\n",
    "\n",
    "    ham_freq = ham_count / ham_size if ham_size > 0 else 0\n",
    "    spam_freq = spam_count / spam_size if spam_size > 0 else 0\n",
    "\n",
    "    # A simple spam-likelihood score (higher â†’ more spammy)\n",
    "    spam_likelihood = (spam_freq + 1e-9) / (ham_freq + spam_freq + 1e-9)\n",
    "\n",
    "    rows.append([word, ham_count, spam_count, ham_freq, spam_freq, spam_likelihood])\n",
    "\n",
    "word_dataset = pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\"word\", \"ham_count\", \"spam_count\", \"ham_freq\", \"spam_freq\", \"spam_likelihood\"]\n",
    ")\n",
    "\n",
    "# Sort by how strongly a word is associated with spam\n",
    "word_dataset_sorted = word_dataset.sort_values(\"spam_likelihood\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Accuracy: 97.590%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      0.97      0.98      1325\n",
      "        spam       0.91      1.00      0.95       418\n",
      "\n",
      "    accuracy                           0.98      1743\n",
      "   macro avg       0.95      0.98      0.97      1743\n",
      "weighted avg       0.98      0.98      0.98      1743\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>svm_spam_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3446</th>\n",
       "      <td>60p</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7450</th>\n",
       "      <td>admirer</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7426</th>\n",
       "      <td>0870</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8252</th>\n",
       "      <td>10p</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3458</th>\n",
       "      <td>08718720201</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3501</th>\n",
       "      <td>200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3506</th>\n",
       "      <td>polys</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>holder</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7439</th>\n",
       "      <td>09050090044</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3353</th>\n",
       "      <td>ringtones</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>std</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>350</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>toclaim</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3326</th>\n",
       "      <td>biz</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>national</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>2004</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7354</th>\n",
       "      <td>3510i</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7328</th>\n",
       "      <td>poly</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8279</th>\n",
       "      <td>cc</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8280</th>\n",
       "      <td>operator</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  svm_spam_probability\n",
       "3446          60p                   1.0\n",
       "7450      admirer                   1.0\n",
       "7426         0870                   1.0\n",
       "8252          10p                   1.0\n",
       "3458  08718720201                   1.0\n",
       "3501          200                   1.0\n",
       "3506        polys                   1.0\n",
       "1235       holder                   1.0\n",
       "7439  09050090044                   1.0\n",
       "3353    ringtones                   1.0\n",
       "3524          std                   1.0\n",
       "1120          350                   1.0\n",
       "3319      toclaim                   1.0\n",
       "3326          biz                   1.0\n",
       "3330     national                   1.0\n",
       "3271         2004                   1.0\n",
       "7354        3510i                   1.0\n",
       "7328         poly                   1.0\n",
       "8279           cc                   1.0\n",
       "8280     operator                   1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create train and test datasets\n",
    "word_dataset_sorted['label'] = (word_dataset_sorted['spam_count'] > word_dataset_sorted['ham_count']).astype(int)\n",
    "feature_cols = [\"ham_freq\", \"spam_freq\", \"ham_count\", \"spam_count\"]\n",
    "X = word_dataset_sorted[feature_cols]\n",
    "y = word_dataset_sorted['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# Train SVM\n",
    "svm_model = Pipeline([(\"scaler\", StandardScaler()), (\"svm\", SVC(kernel=\"rbf\", probability=True))])\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate SVM\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(\"\\nSVM Accuracy: {:.3f}%\".format(accuracy_score(y_test, y_pred) * 100))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"ham\", \"spam\"]))\n",
    "\n",
    "# Tie SVM predictions back to dataset\n",
    "word_dataset_sorted[\"svm_pred\"] = svm_model.predict(X)\n",
    "word_dataset_sorted[\"svm_spam_probability\"] = svm_model.predict_proba(X)[:,1]\n",
    "\n",
    "# Printout of the most likely spam words\n",
    "svm_sorted_words = word_dataset_sorted.sort_values(\"svm_spam_probability\", ascending=False)\n",
    "svm_sorted_words[[\"word\", \"svm_spam_probability\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
